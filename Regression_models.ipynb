{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "from pandas import DataFrame\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "from sklearn.metrics  import classification_report  \n",
    "from sklearn.metrics import confusion_matrix  \n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "\n",
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "#rom sklearn.ensemble import RandomTreesEmbedding\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "from sklearn.linear_model import ARDRegression\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "from sklearn.linear_model import Lars\n",
    "from sklearn.linear_model import LarsCV\n",
    "from sklearn.linear_model import LassoLars\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.linear_model import PassiveAggressiveRegressor\n",
    "from sklearn.linear_model import RANSACRegressor\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import SGDRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>...</th>\n",
       "      <th>X91</th>\n",
       "      <th>X92</th>\n",
       "      <th>X93</th>\n",
       "      <th>X94</th>\n",
       "      <th>X95</th>\n",
       "      <th>X96</th>\n",
       "      <th>X97</th>\n",
       "      <th>X98</th>\n",
       "      <th>X99</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.644887</td>\n",
       "      <td>-0.838461</td>\n",
       "      <td>-0.541017</td>\n",
       "      <td>-0.206648</td>\n",
       "      <td>1.077663</td>\n",
       "      <td>0.596810</td>\n",
       "      <td>1.153668</td>\n",
       "      <td>-0.650632</td>\n",
       "      <td>0.891848</td>\n",
       "      <td>0.951259</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.447763</td>\n",
       "      <td>0.742208</td>\n",
       "      <td>1.006131</td>\n",
       "      <td>1.256626</td>\n",
       "      <td>0.267859</td>\n",
       "      <td>0.428748</td>\n",
       "      <td>-0.123292</td>\n",
       "      <td>1.618648</td>\n",
       "      <td>-1.924411</td>\n",
       "      <td>-22.754639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.632308</td>\n",
       "      <td>0.682364</td>\n",
       "      <td>0.326717</td>\n",
       "      <td>-0.319301</td>\n",
       "      <td>-1.271478</td>\n",
       "      <td>-0.526292</td>\n",
       "      <td>-0.213767</td>\n",
       "      <td>0.472607</td>\n",
       "      <td>-0.948157</td>\n",
       "      <td>-0.460615</td>\n",
       "      <td>...</td>\n",
       "      <td>0.927940</td>\n",
       "      <td>1.726629</td>\n",
       "      <td>-1.013680</td>\n",
       "      <td>0.658450</td>\n",
       "      <td>0.591374</td>\n",
       "      <td>-1.037313</td>\n",
       "      <td>2.038828</td>\n",
       "      <td>-1.740729</td>\n",
       "      <td>-0.498542</td>\n",
       "      <td>224.417071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.661249</td>\n",
       "      <td>0.749986</td>\n",
       "      <td>0.783604</td>\n",
       "      <td>0.330767</td>\n",
       "      <td>0.293766</td>\n",
       "      <td>0.341772</td>\n",
       "      <td>-0.284628</td>\n",
       "      <td>0.956176</td>\n",
       "      <td>-0.285018</td>\n",
       "      <td>-0.315171</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111296</td>\n",
       "      <td>0.141157</td>\n",
       "      <td>-0.860615</td>\n",
       "      <td>-1.078683</td>\n",
       "      <td>0.104910</td>\n",
       "      <td>1.973838</td>\n",
       "      <td>-1.676265</td>\n",
       "      <td>-0.429156</td>\n",
       "      <td>0.338231</td>\n",
       "      <td>23.856344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.403724</td>\n",
       "      <td>-0.335054</td>\n",
       "      <td>0.579087</td>\n",
       "      <td>-0.571980</td>\n",
       "      <td>-0.751977</td>\n",
       "      <td>-0.788276</td>\n",
       "      <td>0.793930</td>\n",
       "      <td>-0.309679</td>\n",
       "      <td>-0.114218</td>\n",
       "      <td>-0.232603</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.324332</td>\n",
       "      <td>1.053042</td>\n",
       "      <td>-0.851262</td>\n",
       "      <td>-0.667930</td>\n",
       "      <td>0.420755</td>\n",
       "      <td>-2.160269</td>\n",
       "      <td>-0.674017</td>\n",
       "      <td>1.472002</td>\n",
       "      <td>0.380672</td>\n",
       "      <td>109.627237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.485241</td>\n",
       "      <td>0.324000</td>\n",
       "      <td>-1.005675</td>\n",
       "      <td>-0.605008</td>\n",
       "      <td>0.119690</td>\n",
       "      <td>0.022500</td>\n",
       "      <td>-0.939901</td>\n",
       "      <td>1.734745</td>\n",
       "      <td>0.647245</td>\n",
       "      <td>0.830049</td>\n",
       "      <td>...</td>\n",
       "      <td>0.258716</td>\n",
       "      <td>1.666226</td>\n",
       "      <td>1.420689</td>\n",
       "      <td>0.992014</td>\n",
       "      <td>0.091870</td>\n",
       "      <td>2.226810</td>\n",
       "      <td>0.791382</td>\n",
       "      <td>-0.153370</td>\n",
       "      <td>0.436515</td>\n",
       "      <td>112.931349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>-0.148490</td>\n",
       "      <td>1.693809</td>\n",
       "      <td>-1.565738</td>\n",
       "      <td>1.760415</td>\n",
       "      <td>0.107343</td>\n",
       "      <td>-0.177632</td>\n",
       "      <td>-1.787913</td>\n",
       "      <td>0.382715</td>\n",
       "      <td>-1.637450</td>\n",
       "      <td>0.169869</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.353410</td>\n",
       "      <td>0.142251</td>\n",
       "      <td>1.384991</td>\n",
       "      <td>-0.870008</td>\n",
       "      <td>-0.799547</td>\n",
       "      <td>-0.731531</td>\n",
       "      <td>-0.806185</td>\n",
       "      <td>0.557439</td>\n",
       "      <td>0.196870</td>\n",
       "      <td>-234.191484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>-0.949864</td>\n",
       "      <td>-0.621252</td>\n",
       "      <td>0.505054</td>\n",
       "      <td>0.814625</td>\n",
       "      <td>-0.924541</td>\n",
       "      <td>-0.429386</td>\n",
       "      <td>-0.261202</td>\n",
       "      <td>0.046846</td>\n",
       "      <td>0.858011</td>\n",
       "      <td>0.459782</td>\n",
       "      <td>...</td>\n",
       "      <td>0.177946</td>\n",
       "      <td>-0.701649</td>\n",
       "      <td>-1.086301</td>\n",
       "      <td>1.127751</td>\n",
       "      <td>-1.279426</td>\n",
       "      <td>-0.130195</td>\n",
       "      <td>-0.185811</td>\n",
       "      <td>0.327068</td>\n",
       "      <td>1.050615</td>\n",
       "      <td>-155.852594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.219249</td>\n",
       "      <td>0.442575</td>\n",
       "      <td>0.092104</td>\n",
       "      <td>0.314288</td>\n",
       "      <td>0.437772</td>\n",
       "      <td>0.055054</td>\n",
       "      <td>-1.275508</td>\n",
       "      <td>1.305157</td>\n",
       "      <td>-0.942368</td>\n",
       "      <td>1.101025</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.432141</td>\n",
       "      <td>-0.796727</td>\n",
       "      <td>0.125273</td>\n",
       "      <td>0.424846</td>\n",
       "      <td>1.225526</td>\n",
       "      <td>0.493698</td>\n",
       "      <td>-0.500715</td>\n",
       "      <td>0.147472</td>\n",
       "      <td>-1.786110</td>\n",
       "      <td>259.366468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2.017390</td>\n",
       "      <td>0.094415</td>\n",
       "      <td>0.307489</td>\n",
       "      <td>0.587450</td>\n",
       "      <td>0.699589</td>\n",
       "      <td>-0.161504</td>\n",
       "      <td>1.883030</td>\n",
       "      <td>0.525360</td>\n",
       "      <td>0.785062</td>\n",
       "      <td>-1.835899</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.628799</td>\n",
       "      <td>-0.441302</td>\n",
       "      <td>-1.301066</td>\n",
       "      <td>-1.337402</td>\n",
       "      <td>-0.659326</td>\n",
       "      <td>0.042317</td>\n",
       "      <td>0.121978</td>\n",
       "      <td>0.331694</td>\n",
       "      <td>-1.456690</td>\n",
       "      <td>-91.824344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>-0.172222</td>\n",
       "      <td>-0.353857</td>\n",
       "      <td>-1.042769</td>\n",
       "      <td>-0.005777</td>\n",
       "      <td>1.832996</td>\n",
       "      <td>-0.341348</td>\n",
       "      <td>1.428931</td>\n",
       "      <td>-0.823251</td>\n",
       "      <td>-1.411615</td>\n",
       "      <td>0.333570</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.060633</td>\n",
       "      <td>-0.827209</td>\n",
       "      <td>-1.258697</td>\n",
       "      <td>-1.192660</td>\n",
       "      <td>-0.032599</td>\n",
       "      <td>-1.668723</td>\n",
       "      <td>0.115748</td>\n",
       "      <td>0.732320</td>\n",
       "      <td>-0.009382</td>\n",
       "      <td>-85.688192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          X0        X1        X2        X3        X4        X5        X6  \\\n",
       "0  -0.644887 -0.838461 -0.541017 -0.206648  1.077663  0.596810  1.153668   \n",
       "1   0.632308  0.682364  0.326717 -0.319301 -1.271478 -0.526292 -0.213767   \n",
       "2   0.661249  0.749986  0.783604  0.330767  0.293766  0.341772 -0.284628   \n",
       "3   0.403724 -0.335054  0.579087 -0.571980 -0.751977 -0.788276  0.793930   \n",
       "4   0.485241  0.324000 -1.005675 -0.605008  0.119690  0.022500 -0.939901   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "95 -0.148490  1.693809 -1.565738  1.760415  0.107343 -0.177632 -1.787913   \n",
       "96 -0.949864 -0.621252  0.505054  0.814625 -0.924541 -0.429386 -0.261202   \n",
       "97  0.219249  0.442575  0.092104  0.314288  0.437772  0.055054 -1.275508   \n",
       "98  2.017390  0.094415  0.307489  0.587450  0.699589 -0.161504  1.883030   \n",
       "99 -0.172222 -0.353857 -1.042769 -0.005777  1.832996 -0.341348  1.428931   \n",
       "\n",
       "          X7        X8        X9  ...       X91       X92       X93       X94  \\\n",
       "0  -0.650632  0.891848  0.951259  ... -0.447763  0.742208  1.006131  1.256626   \n",
       "1   0.472607 -0.948157 -0.460615  ...  0.927940  1.726629 -1.013680  0.658450   \n",
       "2   0.956176 -0.285018 -0.315171  ...  0.111296  0.141157 -0.860615 -1.078683   \n",
       "3  -0.309679 -0.114218 -0.232603  ... -0.324332  1.053042 -0.851262 -0.667930   \n",
       "4   1.734745  0.647245  0.830049  ...  0.258716  1.666226  1.420689  0.992014   \n",
       "..       ...       ...       ...  ...       ...       ...       ...       ...   \n",
       "95  0.382715 -1.637450  0.169869  ... -0.353410  0.142251  1.384991 -0.870008   \n",
       "96  0.046846  0.858011  0.459782  ...  0.177946 -0.701649 -1.086301  1.127751   \n",
       "97  1.305157 -0.942368  1.101025  ... -1.432141 -0.796727  0.125273  0.424846   \n",
       "98  0.525360  0.785062 -1.835899  ... -0.628799 -0.441302 -1.301066 -1.337402   \n",
       "99 -0.823251 -1.411615  0.333570  ... -1.060633 -0.827209 -1.258697 -1.192660   \n",
       "\n",
       "         X95       X96       X97       X98       X99           Y  \n",
       "0   0.267859  0.428748 -0.123292  1.618648 -1.924411  -22.754639  \n",
       "1   0.591374 -1.037313  2.038828 -1.740729 -0.498542  224.417071  \n",
       "2   0.104910  1.973838 -1.676265 -0.429156  0.338231   23.856344  \n",
       "3   0.420755 -2.160269 -0.674017  1.472002  0.380672  109.627237  \n",
       "4   0.091870  2.226810  0.791382 -0.153370  0.436515  112.931349  \n",
       "..       ...       ...       ...       ...       ...         ...  \n",
       "95 -0.799547 -0.731531 -0.806185  0.557439  0.196870 -234.191484  \n",
       "96 -1.279426 -0.130195 -0.185811  0.327068  1.050615 -155.852594  \n",
       "97  1.225526  0.493698 -0.500715  0.147472 -1.786110  259.366468  \n",
       "98 -0.659326  0.042317  0.121978  0.331694 -1.456690  -91.824344  \n",
       "99 -0.032599 -1.668723  0.115748  0.732320 -0.009382  -85.688192  \n",
       "\n",
       "[100 rows x 101 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Формируем данные исходных dataset\n",
    "\n",
    "X, Y = make_regression(n_samples = 100, n_features=100, n_informative=5, random_state=1)\n",
    "X = pd.DataFrame(X)\n",
    "Y = pd.DataFrame(Y)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "LIST_NAME_FEATURES = []\n",
    "LIST_NAME_Y = []\n",
    "\n",
    "# Фичи\n",
    "for index, name in enumerate(X.columns):\n",
    "    LIST_NAME_FEATURES.append(f\"X{index}\")\n",
    "    df[f\"X{index}\"] = X[index]\n",
    "    \n",
    "# Y\n",
    "for index, name in enumerate(Y.columns):\n",
    "    LIST_NAME_Y.append(f\"Y\")\n",
    "    df[f\"Y\"] = Y[index]\n",
    "\n",
    "# Убираем nan\n",
    "df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>...</th>\n",
       "      <th>X91</th>\n",
       "      <th>X92</th>\n",
       "      <th>X93</th>\n",
       "      <th>X94</th>\n",
       "      <th>X95</th>\n",
       "      <th>X96</th>\n",
       "      <th>X97</th>\n",
       "      <th>X98</th>\n",
       "      <th>X99</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>X0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.010014</td>\n",
       "      <td>0.092172</td>\n",
       "      <td>0.011947</td>\n",
       "      <td>0.151448</td>\n",
       "      <td>-0.195936</td>\n",
       "      <td>-0.048167</td>\n",
       "      <td>0.175704</td>\n",
       "      <td>-0.008126</td>\n",
       "      <td>-0.103832</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045154</td>\n",
       "      <td>-0.034100</td>\n",
       "      <td>-0.134661</td>\n",
       "      <td>0.031930</td>\n",
       "      <td>-0.040693</td>\n",
       "      <td>-0.035144</td>\n",
       "      <td>-0.023335</td>\n",
       "      <td>-0.073500</td>\n",
       "      <td>0.005303</td>\n",
       "      <td>-0.104887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X1</th>\n",
       "      <td>-0.010014</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.062210</td>\n",
       "      <td>0.018935</td>\n",
       "      <td>-0.027149</td>\n",
       "      <td>-0.009473</td>\n",
       "      <td>0.042440</td>\n",
       "      <td>0.056946</td>\n",
       "      <td>-0.059718</td>\n",
       "      <td>0.062481</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069194</td>\n",
       "      <td>-0.002691</td>\n",
       "      <td>0.152360</td>\n",
       "      <td>-0.042473</td>\n",
       "      <td>0.023381</td>\n",
       "      <td>0.046189</td>\n",
       "      <td>0.045317</td>\n",
       "      <td>-0.112236</td>\n",
       "      <td>-0.062296</td>\n",
       "      <td>-0.053069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X2</th>\n",
       "      <td>0.092172</td>\n",
       "      <td>-0.062210</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.071154</td>\n",
       "      <td>-0.115315</td>\n",
       "      <td>-0.072149</td>\n",
       "      <td>0.168184</td>\n",
       "      <td>-0.039881</td>\n",
       "      <td>-0.013415</td>\n",
       "      <td>-0.224493</td>\n",
       "      <td>...</td>\n",
       "      <td>0.229958</td>\n",
       "      <td>-0.167620</td>\n",
       "      <td>-0.234668</td>\n",
       "      <td>0.006538</td>\n",
       "      <td>0.026246</td>\n",
       "      <td>-0.070603</td>\n",
       "      <td>0.048558</td>\n",
       "      <td>-0.105144</td>\n",
       "      <td>0.141599</td>\n",
       "      <td>0.056904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X3</th>\n",
       "      <td>0.011947</td>\n",
       "      <td>0.018935</td>\n",
       "      <td>-0.071154</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.152766</td>\n",
       "      <td>-0.075146</td>\n",
       "      <td>-0.042260</td>\n",
       "      <td>0.010289</td>\n",
       "      <td>0.116488</td>\n",
       "      <td>0.018236</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.080681</td>\n",
       "      <td>0.023015</td>\n",
       "      <td>-0.078256</td>\n",
       "      <td>-0.032208</td>\n",
       "      <td>-0.134195</td>\n",
       "      <td>-0.082318</td>\n",
       "      <td>-0.126365</td>\n",
       "      <td>-0.047258</td>\n",
       "      <td>0.016019</td>\n",
       "      <td>-0.154389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X4</th>\n",
       "      <td>0.151448</td>\n",
       "      <td>-0.027149</td>\n",
       "      <td>-0.115315</td>\n",
       "      <td>0.152766</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.025085</td>\n",
       "      <td>0.132409</td>\n",
       "      <td>0.041355</td>\n",
       "      <td>-0.023041</td>\n",
       "      <td>0.117096</td>\n",
       "      <td>...</td>\n",
       "      <td>0.116022</td>\n",
       "      <td>-0.189538</td>\n",
       "      <td>0.052951</td>\n",
       "      <td>-0.046279</td>\n",
       "      <td>-0.171893</td>\n",
       "      <td>-0.033547</td>\n",
       "      <td>-0.100234</td>\n",
       "      <td>-0.050803</td>\n",
       "      <td>-0.048351</td>\n",
       "      <td>-0.179577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X96</th>\n",
       "      <td>-0.035144</td>\n",
       "      <td>0.046189</td>\n",
       "      <td>-0.070603</td>\n",
       "      <td>-0.082318</td>\n",
       "      <td>-0.033547</td>\n",
       "      <td>0.087868</td>\n",
       "      <td>-0.102328</td>\n",
       "      <td>0.150068</td>\n",
       "      <td>0.012029</td>\n",
       "      <td>0.070752</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.152843</td>\n",
       "      <td>0.089077</td>\n",
       "      <td>0.121705</td>\n",
       "      <td>0.032961</td>\n",
       "      <td>-0.083148</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.038404</td>\n",
       "      <td>-0.083822</td>\n",
       "      <td>0.171704</td>\n",
       "      <td>0.061191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X97</th>\n",
       "      <td>-0.023335</td>\n",
       "      <td>0.045317</td>\n",
       "      <td>0.048558</td>\n",
       "      <td>-0.126365</td>\n",
       "      <td>-0.100234</td>\n",
       "      <td>0.142227</td>\n",
       "      <td>-0.067921</td>\n",
       "      <td>-0.077798</td>\n",
       "      <td>-0.039944</td>\n",
       "      <td>0.036435</td>\n",
       "      <td>...</td>\n",
       "      <td>0.182051</td>\n",
       "      <td>0.150968</td>\n",
       "      <td>0.093849</td>\n",
       "      <td>0.077555</td>\n",
       "      <td>0.077281</td>\n",
       "      <td>-0.038404</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.032429</td>\n",
       "      <td>-0.017986</td>\n",
       "      <td>-0.066397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X98</th>\n",
       "      <td>-0.073500</td>\n",
       "      <td>-0.112236</td>\n",
       "      <td>-0.105144</td>\n",
       "      <td>-0.047258</td>\n",
       "      <td>-0.050803</td>\n",
       "      <td>0.145612</td>\n",
       "      <td>-0.014938</td>\n",
       "      <td>-0.083404</td>\n",
       "      <td>0.143018</td>\n",
       "      <td>0.116797</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.093546</td>\n",
       "      <td>0.176527</td>\n",
       "      <td>-0.178782</td>\n",
       "      <td>0.062818</td>\n",
       "      <td>-0.066062</td>\n",
       "      <td>-0.083822</td>\n",
       "      <td>0.032429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.061622</td>\n",
       "      <td>-0.194194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X99</th>\n",
       "      <td>0.005303</td>\n",
       "      <td>-0.062296</td>\n",
       "      <td>0.141599</td>\n",
       "      <td>0.016019</td>\n",
       "      <td>-0.048351</td>\n",
       "      <td>-0.100233</td>\n",
       "      <td>-0.066822</td>\n",
       "      <td>-0.145136</td>\n",
       "      <td>-0.069258</td>\n",
       "      <td>0.077879</td>\n",
       "      <td>...</td>\n",
       "      <td>0.158555</td>\n",
       "      <td>0.039558</td>\n",
       "      <td>0.068627</td>\n",
       "      <td>0.016889</td>\n",
       "      <td>0.010349</td>\n",
       "      <td>0.171704</td>\n",
       "      <td>-0.017986</td>\n",
       "      <td>0.061622</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.079138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Y</th>\n",
       "      <td>-0.104887</td>\n",
       "      <td>-0.053069</td>\n",
       "      <td>0.056904</td>\n",
       "      <td>-0.154389</td>\n",
       "      <td>-0.179577</td>\n",
       "      <td>-0.005831</td>\n",
       "      <td>0.151166</td>\n",
       "      <td>-0.055897</td>\n",
       "      <td>-0.041623</td>\n",
       "      <td>-0.023991</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018614</td>\n",
       "      <td>-0.062410</td>\n",
       "      <td>-0.034759</td>\n",
       "      <td>-0.018968</td>\n",
       "      <td>0.726996</td>\n",
       "      <td>0.061191</td>\n",
       "      <td>-0.066397</td>\n",
       "      <td>-0.194194</td>\n",
       "      <td>-0.079138</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           X0        X1        X2        X3        X4        X5        X6  \\\n",
       "X0   1.000000 -0.010014  0.092172  0.011947  0.151448 -0.195936 -0.048167   \n",
       "X1  -0.010014  1.000000 -0.062210  0.018935 -0.027149 -0.009473  0.042440   \n",
       "X2   0.092172 -0.062210  1.000000 -0.071154 -0.115315 -0.072149  0.168184   \n",
       "X3   0.011947  0.018935 -0.071154  1.000000  0.152766 -0.075146 -0.042260   \n",
       "X4   0.151448 -0.027149 -0.115315  0.152766  1.000000 -0.025085  0.132409   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "X96 -0.035144  0.046189 -0.070603 -0.082318 -0.033547  0.087868 -0.102328   \n",
       "X97 -0.023335  0.045317  0.048558 -0.126365 -0.100234  0.142227 -0.067921   \n",
       "X98 -0.073500 -0.112236 -0.105144 -0.047258 -0.050803  0.145612 -0.014938   \n",
       "X99  0.005303 -0.062296  0.141599  0.016019 -0.048351 -0.100233 -0.066822   \n",
       "Y   -0.104887 -0.053069  0.056904 -0.154389 -0.179577 -0.005831  0.151166   \n",
       "\n",
       "           X7        X8        X9  ...       X91       X92       X93  \\\n",
       "X0   0.175704 -0.008126 -0.103832  ...  0.045154 -0.034100 -0.134661   \n",
       "X1   0.056946 -0.059718  0.062481  ...  0.069194 -0.002691  0.152360   \n",
       "X2  -0.039881 -0.013415 -0.224493  ...  0.229958 -0.167620 -0.234668   \n",
       "X3   0.010289  0.116488  0.018236  ... -0.080681  0.023015 -0.078256   \n",
       "X4   0.041355 -0.023041  0.117096  ...  0.116022 -0.189538  0.052951   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "X96  0.150068  0.012029  0.070752  ... -0.152843  0.089077  0.121705   \n",
       "X97 -0.077798 -0.039944  0.036435  ...  0.182051  0.150968  0.093849   \n",
       "X98 -0.083404  0.143018  0.116797  ... -0.093546  0.176527 -0.178782   \n",
       "X99 -0.145136 -0.069258  0.077879  ...  0.158555  0.039558  0.068627   \n",
       "Y   -0.055897 -0.041623 -0.023991  ... -0.018614 -0.062410 -0.034759   \n",
       "\n",
       "          X94       X95       X96       X97       X98       X99         Y  \n",
       "X0   0.031930 -0.040693 -0.035144 -0.023335 -0.073500  0.005303 -0.104887  \n",
       "X1  -0.042473  0.023381  0.046189  0.045317 -0.112236 -0.062296 -0.053069  \n",
       "X2   0.006538  0.026246 -0.070603  0.048558 -0.105144  0.141599  0.056904  \n",
       "X3  -0.032208 -0.134195 -0.082318 -0.126365 -0.047258  0.016019 -0.154389  \n",
       "X4  -0.046279 -0.171893 -0.033547 -0.100234 -0.050803 -0.048351 -0.179577  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "X96  0.032961 -0.083148  1.000000 -0.038404 -0.083822  0.171704  0.061191  \n",
       "X97  0.077555  0.077281 -0.038404  1.000000  0.032429 -0.017986 -0.066397  \n",
       "X98  0.062818 -0.066062 -0.083822  0.032429  1.000000  0.061622 -0.194194  \n",
       "X99  0.016889  0.010349  0.171704 -0.017986  0.061622  1.000000 -0.079138  \n",
       "Y   -0.018968  0.726996  0.061191 -0.066397 -0.194194 -0.079138  1.000000  \n",
       "\n",
       "[101 rows x 101 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>...</th>\n",
       "      <th>X91</th>\n",
       "      <th>X92</th>\n",
       "      <th>X93</th>\n",
       "      <th>X94</th>\n",
       "      <th>X95</th>\n",
       "      <th>X96</th>\n",
       "      <th>X97</th>\n",
       "      <th>X98</th>\n",
       "      <th>X99</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.644887</td>\n",
       "      <td>-0.838461</td>\n",
       "      <td>-0.541017</td>\n",
       "      <td>-0.206648</td>\n",
       "      <td>1.077663</td>\n",
       "      <td>0.596810</td>\n",
       "      <td>1.153668</td>\n",
       "      <td>-0.650632</td>\n",
       "      <td>0.891848</td>\n",
       "      <td>0.951259</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.447763</td>\n",
       "      <td>0.742208</td>\n",
       "      <td>1.006131</td>\n",
       "      <td>1.256626</td>\n",
       "      <td>0.267859</td>\n",
       "      <td>0.428748</td>\n",
       "      <td>-0.123292</td>\n",
       "      <td>1.618648</td>\n",
       "      <td>-1.924411</td>\n",
       "      <td>-22.754639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.632308</td>\n",
       "      <td>0.682364</td>\n",
       "      <td>0.326717</td>\n",
       "      <td>-0.319301</td>\n",
       "      <td>-1.271478</td>\n",
       "      <td>-0.526292</td>\n",
       "      <td>-0.213767</td>\n",
       "      <td>0.472607</td>\n",
       "      <td>-0.948157</td>\n",
       "      <td>-0.460615</td>\n",
       "      <td>...</td>\n",
       "      <td>0.927940</td>\n",
       "      <td>1.726629</td>\n",
       "      <td>-1.013680</td>\n",
       "      <td>0.658450</td>\n",
       "      <td>0.591374</td>\n",
       "      <td>-1.037313</td>\n",
       "      <td>2.038828</td>\n",
       "      <td>-1.740729</td>\n",
       "      <td>-0.498542</td>\n",
       "      <td>224.417071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.661249</td>\n",
       "      <td>0.749986</td>\n",
       "      <td>0.783604</td>\n",
       "      <td>0.330767</td>\n",
       "      <td>0.293766</td>\n",
       "      <td>0.341772</td>\n",
       "      <td>-0.284628</td>\n",
       "      <td>0.956176</td>\n",
       "      <td>-0.285018</td>\n",
       "      <td>-0.315171</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111296</td>\n",
       "      <td>0.141157</td>\n",
       "      <td>-0.860615</td>\n",
       "      <td>-1.078683</td>\n",
       "      <td>0.104910</td>\n",
       "      <td>1.973838</td>\n",
       "      <td>-1.676265</td>\n",
       "      <td>-0.429156</td>\n",
       "      <td>0.338231</td>\n",
       "      <td>23.856344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.403724</td>\n",
       "      <td>-0.335054</td>\n",
       "      <td>0.579087</td>\n",
       "      <td>-0.571980</td>\n",
       "      <td>-0.751977</td>\n",
       "      <td>-0.788276</td>\n",
       "      <td>0.793930</td>\n",
       "      <td>-0.309679</td>\n",
       "      <td>-0.114218</td>\n",
       "      <td>-0.232603</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.324332</td>\n",
       "      <td>1.053042</td>\n",
       "      <td>-0.851262</td>\n",
       "      <td>-0.667930</td>\n",
       "      <td>0.420755</td>\n",
       "      <td>-2.160269</td>\n",
       "      <td>-0.674017</td>\n",
       "      <td>1.472002</td>\n",
       "      <td>0.380672</td>\n",
       "      <td>109.627237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.485241</td>\n",
       "      <td>0.324000</td>\n",
       "      <td>-1.005675</td>\n",
       "      <td>-0.605008</td>\n",
       "      <td>0.119690</td>\n",
       "      <td>0.022500</td>\n",
       "      <td>-0.939901</td>\n",
       "      <td>1.734745</td>\n",
       "      <td>0.647245</td>\n",
       "      <td>0.830049</td>\n",
       "      <td>...</td>\n",
       "      <td>0.258716</td>\n",
       "      <td>1.666226</td>\n",
       "      <td>1.420689</td>\n",
       "      <td>0.992014</td>\n",
       "      <td>0.091870</td>\n",
       "      <td>2.226810</td>\n",
       "      <td>0.791382</td>\n",
       "      <td>-0.153370</td>\n",
       "      <td>0.436515</td>\n",
       "      <td>112.931349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>-0.148490</td>\n",
       "      <td>1.693809</td>\n",
       "      <td>-1.565738</td>\n",
       "      <td>1.760415</td>\n",
       "      <td>0.107343</td>\n",
       "      <td>-0.177632</td>\n",
       "      <td>-1.787913</td>\n",
       "      <td>0.382715</td>\n",
       "      <td>-1.637450</td>\n",
       "      <td>0.169869</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.353410</td>\n",
       "      <td>0.142251</td>\n",
       "      <td>1.384991</td>\n",
       "      <td>-0.870008</td>\n",
       "      <td>-0.799547</td>\n",
       "      <td>-0.731531</td>\n",
       "      <td>-0.806185</td>\n",
       "      <td>0.557439</td>\n",
       "      <td>0.196870</td>\n",
       "      <td>-234.191484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>-0.949864</td>\n",
       "      <td>-0.621252</td>\n",
       "      <td>0.505054</td>\n",
       "      <td>0.814625</td>\n",
       "      <td>-0.924541</td>\n",
       "      <td>-0.429386</td>\n",
       "      <td>-0.261202</td>\n",
       "      <td>0.046846</td>\n",
       "      <td>0.858011</td>\n",
       "      <td>0.459782</td>\n",
       "      <td>...</td>\n",
       "      <td>0.177946</td>\n",
       "      <td>-0.701649</td>\n",
       "      <td>-1.086301</td>\n",
       "      <td>1.127751</td>\n",
       "      <td>-1.279426</td>\n",
       "      <td>-0.130195</td>\n",
       "      <td>-0.185811</td>\n",
       "      <td>0.327068</td>\n",
       "      <td>1.050615</td>\n",
       "      <td>-155.852594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.219249</td>\n",
       "      <td>0.442575</td>\n",
       "      <td>0.092104</td>\n",
       "      <td>0.314288</td>\n",
       "      <td>0.437772</td>\n",
       "      <td>0.055054</td>\n",
       "      <td>-1.275508</td>\n",
       "      <td>1.305157</td>\n",
       "      <td>-0.942368</td>\n",
       "      <td>1.101025</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.432141</td>\n",
       "      <td>-0.796727</td>\n",
       "      <td>0.125273</td>\n",
       "      <td>0.424846</td>\n",
       "      <td>1.225526</td>\n",
       "      <td>0.493698</td>\n",
       "      <td>-0.500715</td>\n",
       "      <td>0.147472</td>\n",
       "      <td>-1.786110</td>\n",
       "      <td>259.366468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2.017390</td>\n",
       "      <td>0.094415</td>\n",
       "      <td>0.307489</td>\n",
       "      <td>0.587450</td>\n",
       "      <td>0.699589</td>\n",
       "      <td>-0.161504</td>\n",
       "      <td>1.883030</td>\n",
       "      <td>0.525360</td>\n",
       "      <td>0.785062</td>\n",
       "      <td>-1.835899</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.628799</td>\n",
       "      <td>-0.441302</td>\n",
       "      <td>-1.301066</td>\n",
       "      <td>-1.337402</td>\n",
       "      <td>-0.659326</td>\n",
       "      <td>0.042317</td>\n",
       "      <td>0.121978</td>\n",
       "      <td>0.331694</td>\n",
       "      <td>-1.456690</td>\n",
       "      <td>-91.824344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>-0.172222</td>\n",
       "      <td>-0.353857</td>\n",
       "      <td>-1.042769</td>\n",
       "      <td>-0.005777</td>\n",
       "      <td>1.832996</td>\n",
       "      <td>-0.341348</td>\n",
       "      <td>1.428931</td>\n",
       "      <td>-0.823251</td>\n",
       "      <td>-1.411615</td>\n",
       "      <td>0.333570</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.060633</td>\n",
       "      <td>-0.827209</td>\n",
       "      <td>-1.258697</td>\n",
       "      <td>-1.192660</td>\n",
       "      <td>-0.032599</td>\n",
       "      <td>-1.668723</td>\n",
       "      <td>0.115748</td>\n",
       "      <td>0.732320</td>\n",
       "      <td>-0.009382</td>\n",
       "      <td>-85.688192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          X0        X1        X2        X3        X4        X5        X6  \\\n",
       "0  -0.644887 -0.838461 -0.541017 -0.206648  1.077663  0.596810  1.153668   \n",
       "1   0.632308  0.682364  0.326717 -0.319301 -1.271478 -0.526292 -0.213767   \n",
       "2   0.661249  0.749986  0.783604  0.330767  0.293766  0.341772 -0.284628   \n",
       "3   0.403724 -0.335054  0.579087 -0.571980 -0.751977 -0.788276  0.793930   \n",
       "4   0.485241  0.324000 -1.005675 -0.605008  0.119690  0.022500 -0.939901   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "95 -0.148490  1.693809 -1.565738  1.760415  0.107343 -0.177632 -1.787913   \n",
       "96 -0.949864 -0.621252  0.505054  0.814625 -0.924541 -0.429386 -0.261202   \n",
       "97  0.219249  0.442575  0.092104  0.314288  0.437772  0.055054 -1.275508   \n",
       "98  2.017390  0.094415  0.307489  0.587450  0.699589 -0.161504  1.883030   \n",
       "99 -0.172222 -0.353857 -1.042769 -0.005777  1.832996 -0.341348  1.428931   \n",
       "\n",
       "          X7        X8        X9  ...       X91       X92       X93       X94  \\\n",
       "0  -0.650632  0.891848  0.951259  ... -0.447763  0.742208  1.006131  1.256626   \n",
       "1   0.472607 -0.948157 -0.460615  ...  0.927940  1.726629 -1.013680  0.658450   \n",
       "2   0.956176 -0.285018 -0.315171  ...  0.111296  0.141157 -0.860615 -1.078683   \n",
       "3  -0.309679 -0.114218 -0.232603  ... -0.324332  1.053042 -0.851262 -0.667930   \n",
       "4   1.734745  0.647245  0.830049  ...  0.258716  1.666226  1.420689  0.992014   \n",
       "..       ...       ...       ...  ...       ...       ...       ...       ...   \n",
       "95  0.382715 -1.637450  0.169869  ... -0.353410  0.142251  1.384991 -0.870008   \n",
       "96  0.046846  0.858011  0.459782  ...  0.177946 -0.701649 -1.086301  1.127751   \n",
       "97  1.305157 -0.942368  1.101025  ... -1.432141 -0.796727  0.125273  0.424846   \n",
       "98  0.525360  0.785062 -1.835899  ... -0.628799 -0.441302 -1.301066 -1.337402   \n",
       "99 -0.823251 -1.411615  0.333570  ... -1.060633 -0.827209 -1.258697 -1.192660   \n",
       "\n",
       "         X95       X96       X97       X98       X99           Y  \n",
       "0   0.267859  0.428748 -0.123292  1.618648 -1.924411  -22.754639  \n",
       "1   0.591374 -1.037313  2.038828 -1.740729 -0.498542  224.417071  \n",
       "2   0.104910  1.973838 -1.676265 -0.429156  0.338231   23.856344  \n",
       "3   0.420755 -2.160269 -0.674017  1.472002  0.380672  109.627237  \n",
       "4   0.091870  2.226810  0.791382 -0.153370  0.436515  112.931349  \n",
       "..       ...       ...       ...       ...       ...         ...  \n",
       "95 -0.799547 -0.731531 -0.806185  0.557439  0.196870 -234.191484  \n",
       "96 -1.279426 -0.130195 -0.185811  0.327068  1.050615 -155.852594  \n",
       "97  1.225526  0.493698 -0.500715  0.147472 -1.786110  259.366468  \n",
       "98 -0.659326  0.042317  0.121978  0.331694 -1.456690  -91.824344  \n",
       "99 -0.032599 -1.668723  0.115748  0.732320 -0.009382  -85.688192  \n",
       "\n",
       "[100 rows x 101 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Функция для проверки на корреляцию\n",
    "def valid_corr(df, max_corr=0.8):\n",
    "    \n",
    "    # Матрица корреляции элментов\n",
    "    matrix_corr = df.corr()\n",
    "\n",
    "    # Список для хранения параметров, которые буде удалять\n",
    "    corr_list = []\n",
    "\n",
    "    # Добавим в наш список все элеементы корреляция коорых между собой нас не устраивет\n",
    "    for i in range(1, len(matrix_corr)):\n",
    "        for j in range(i + 1, len(matrix_corr) - 1):\n",
    "            #print(f'{f\"X{i}\"} - {f\"X{j}\"} >>> {abs(matrix_corr[f\"X{i}\"][f\"X{j}\"])}')\n",
    "            # Если значение корреляции больше, чем допуспимое значение\n",
    "            if abs(matrix_corr[f\"X{i}\"][f\"X{j}\"]) > max_corr:\n",
    "                \n",
    "                # Смотрим какой из параметров меньше коррелирует с 'y' и добавляем его в список для дальнейшего удаления\n",
    "                if matrix_corr[f\"X{i}\"][\"Y\"] > matrix_corr[f\"X{j}\"][\"Y\"]:\n",
    "                    corr_list.append(f\"X{j}\")\n",
    "                else:\n",
    "                    corr_list.append(f\"X{i}\")\n",
    "\n",
    "#    # Проверим значения, которые никак не коррелируют с 'y'\n",
    "#    for i in range(1, len(matrix_corr[\"Y\"])):\n",
    "#        if isnan(matrix_corr[\"Y\"][f\"X{i}\"]) ==  True: corr_list.append(f\"X{i}\" + str(i))\n",
    "\n",
    "    corr_list = list(set(corr_list)) \n",
    "    print (corr_list)\n",
    "    temp = df.drop (corr_list, axis = 1)\n",
    "    return (temp)\n",
    "valid_corr(df, max_corr=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = df[LIST_NAME_FEATURES]\n",
    "Y = df[LIST_NAME_Y]\n",
    "\n",
    "#X = pd.DataFrame(X)\n",
    "# X = pd.DataFrame(Normalizer().fit(X).transform(X))\n",
    "\n",
    "# Нормализация\n",
    "# X = pd.DataFrame(Normalizer().fit(X).transform(X))\n",
    "\n",
    "# Стандартизация\n",
    "#X = pd.DataFrame(StandardScaler().fit(X).transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 100 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   X0      100 non-null    float64\n",
      " 1   X1      100 non-null    float64\n",
      " 2   X2      100 non-null    float64\n",
      " 3   X3      100 non-null    float64\n",
      " 4   X4      100 non-null    float64\n",
      " 5   X5      100 non-null    float64\n",
      " 6   X6      100 non-null    float64\n",
      " 7   X7      100 non-null    float64\n",
      " 8   X8      100 non-null    float64\n",
      " 9   X9      100 non-null    float64\n",
      " 10  X10     100 non-null    float64\n",
      " 11  X11     100 non-null    float64\n",
      " 12  X12     100 non-null    float64\n",
      " 13  X13     100 non-null    float64\n",
      " 14  X14     100 non-null    float64\n",
      " 15  X15     100 non-null    float64\n",
      " 16  X16     100 non-null    float64\n",
      " 17  X17     100 non-null    float64\n",
      " 18  X18     100 non-null    float64\n",
      " 19  X19     100 non-null    float64\n",
      " 20  X20     100 non-null    float64\n",
      " 21  X21     100 non-null    float64\n",
      " 22  X22     100 non-null    float64\n",
      " 23  X23     100 non-null    float64\n",
      " 24  X24     100 non-null    float64\n",
      " 25  X25     100 non-null    float64\n",
      " 26  X26     100 non-null    float64\n",
      " 27  X27     100 non-null    float64\n",
      " 28  X28     100 non-null    float64\n",
      " 29  X29     100 non-null    float64\n",
      " 30  X30     100 non-null    float64\n",
      " 31  X31     100 non-null    float64\n",
      " 32  X32     100 non-null    float64\n",
      " 33  X33     100 non-null    float64\n",
      " 34  X34     100 non-null    float64\n",
      " 35  X35     100 non-null    float64\n",
      " 36  X36     100 non-null    float64\n",
      " 37  X37     100 non-null    float64\n",
      " 38  X38     100 non-null    float64\n",
      " 39  X39     100 non-null    float64\n",
      " 40  X40     100 non-null    float64\n",
      " 41  X41     100 non-null    float64\n",
      " 42  X42     100 non-null    float64\n",
      " 43  X43     100 non-null    float64\n",
      " 44  X44     100 non-null    float64\n",
      " 45  X45     100 non-null    float64\n",
      " 46  X46     100 non-null    float64\n",
      " 47  X47     100 non-null    float64\n",
      " 48  X48     100 non-null    float64\n",
      " 49  X49     100 non-null    float64\n",
      " 50  X50     100 non-null    float64\n",
      " 51  X51     100 non-null    float64\n",
      " 52  X52     100 non-null    float64\n",
      " 53  X53     100 non-null    float64\n",
      " 54  X54     100 non-null    float64\n",
      " 55  X55     100 non-null    float64\n",
      " 56  X56     100 non-null    float64\n",
      " 57  X57     100 non-null    float64\n",
      " 58  X58     100 non-null    float64\n",
      " 59  X59     100 non-null    float64\n",
      " 60  X60     100 non-null    float64\n",
      " 61  X61     100 non-null    float64\n",
      " 62  X62     100 non-null    float64\n",
      " 63  X63     100 non-null    float64\n",
      " 64  X64     100 non-null    float64\n",
      " 65  X65     100 non-null    float64\n",
      " 66  X66     100 non-null    float64\n",
      " 67  X67     100 non-null    float64\n",
      " 68  X68     100 non-null    float64\n",
      " 69  X69     100 non-null    float64\n",
      " 70  X70     100 non-null    float64\n",
      " 71  X71     100 non-null    float64\n",
      " 72  X72     100 non-null    float64\n",
      " 73  X73     100 non-null    float64\n",
      " 74  X74     100 non-null    float64\n",
      " 75  X75     100 non-null    float64\n",
      " 76  X76     100 non-null    float64\n",
      " 77  X77     100 non-null    float64\n",
      " 78  X78     100 non-null    float64\n",
      " 79  X79     100 non-null    float64\n",
      " 80  X80     100 non-null    float64\n",
      " 81  X81     100 non-null    float64\n",
      " 82  X82     100 non-null    float64\n",
      " 83  X83     100 non-null    float64\n",
      " 84  X84     100 non-null    float64\n",
      " 85  X85     100 non-null    float64\n",
      " 86  X86     100 non-null    float64\n",
      " 87  X87     100 non-null    float64\n",
      " 88  X88     100 non-null    float64\n",
      " 89  X89     100 non-null    float64\n",
      " 90  X90     100 non-null    float64\n",
      " 91  X91     100 non-null    float64\n",
      " 92  X92     100 non-null    float64\n",
      " 93  X93     100 non-null    float64\n",
      " 94  X94     100 non-null    float64\n",
      " 95  X95     100 non-null    float64\n",
      " 96  X96     100 non-null    float64\n",
      " 97  X97     100 non-null    float64\n",
      " 98  X98     100 non-null    float64\n",
      " 99  X99     100 non-null    float64\n",
      "dtypes: float64(100)\n",
      "memory usage: 78.2 KB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 <-> 100\n"
     ]
    }
   ],
   "source": [
    "print (len(X), '<->', len(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>...</th>\n",
       "      <th>X91</th>\n",
       "      <th>X92</th>\n",
       "      <th>X93</th>\n",
       "      <th>X94</th>\n",
       "      <th>X95</th>\n",
       "      <th>X96</th>\n",
       "      <th>X97</th>\n",
       "      <th>X98</th>\n",
       "      <th>X99</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.644887</td>\n",
       "      <td>-0.838461</td>\n",
       "      <td>-0.541017</td>\n",
       "      <td>-0.206648</td>\n",
       "      <td>1.077663</td>\n",
       "      <td>0.596810</td>\n",
       "      <td>1.153668</td>\n",
       "      <td>-0.650632</td>\n",
       "      <td>0.891848</td>\n",
       "      <td>0.951259</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.447763</td>\n",
       "      <td>0.742208</td>\n",
       "      <td>1.006131</td>\n",
       "      <td>1.256626</td>\n",
       "      <td>0.267859</td>\n",
       "      <td>0.428748</td>\n",
       "      <td>-0.123292</td>\n",
       "      <td>1.618648</td>\n",
       "      <td>-1.924411</td>\n",
       "      <td>-22.754639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.632308</td>\n",
       "      <td>0.682364</td>\n",
       "      <td>0.326717</td>\n",
       "      <td>-0.319301</td>\n",
       "      <td>-1.271478</td>\n",
       "      <td>-0.526292</td>\n",
       "      <td>-0.213767</td>\n",
       "      <td>0.472607</td>\n",
       "      <td>-0.948157</td>\n",
       "      <td>-0.460615</td>\n",
       "      <td>...</td>\n",
       "      <td>0.927940</td>\n",
       "      <td>1.726629</td>\n",
       "      <td>-1.013680</td>\n",
       "      <td>0.658450</td>\n",
       "      <td>0.591374</td>\n",
       "      <td>-1.037313</td>\n",
       "      <td>2.038828</td>\n",
       "      <td>-1.740729</td>\n",
       "      <td>-0.498542</td>\n",
       "      <td>224.417071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.661249</td>\n",
       "      <td>0.749986</td>\n",
       "      <td>0.783604</td>\n",
       "      <td>0.330767</td>\n",
       "      <td>0.293766</td>\n",
       "      <td>0.341772</td>\n",
       "      <td>-0.284628</td>\n",
       "      <td>0.956176</td>\n",
       "      <td>-0.285018</td>\n",
       "      <td>-0.315171</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111296</td>\n",
       "      <td>0.141157</td>\n",
       "      <td>-0.860615</td>\n",
       "      <td>-1.078683</td>\n",
       "      <td>0.104910</td>\n",
       "      <td>1.973838</td>\n",
       "      <td>-1.676265</td>\n",
       "      <td>-0.429156</td>\n",
       "      <td>0.338231</td>\n",
       "      <td>23.856344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.403724</td>\n",
       "      <td>-0.335054</td>\n",
       "      <td>0.579087</td>\n",
       "      <td>-0.571980</td>\n",
       "      <td>-0.751977</td>\n",
       "      <td>-0.788276</td>\n",
       "      <td>0.793930</td>\n",
       "      <td>-0.309679</td>\n",
       "      <td>-0.114218</td>\n",
       "      <td>-0.232603</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.324332</td>\n",
       "      <td>1.053042</td>\n",
       "      <td>-0.851262</td>\n",
       "      <td>-0.667930</td>\n",
       "      <td>0.420755</td>\n",
       "      <td>-2.160269</td>\n",
       "      <td>-0.674017</td>\n",
       "      <td>1.472002</td>\n",
       "      <td>0.380672</td>\n",
       "      <td>109.627237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.485241</td>\n",
       "      <td>0.324000</td>\n",
       "      <td>-1.005675</td>\n",
       "      <td>-0.605008</td>\n",
       "      <td>0.119690</td>\n",
       "      <td>0.022500</td>\n",
       "      <td>-0.939901</td>\n",
       "      <td>1.734745</td>\n",
       "      <td>0.647245</td>\n",
       "      <td>0.830049</td>\n",
       "      <td>...</td>\n",
       "      <td>0.258716</td>\n",
       "      <td>1.666226</td>\n",
       "      <td>1.420689</td>\n",
       "      <td>0.992014</td>\n",
       "      <td>0.091870</td>\n",
       "      <td>2.226810</td>\n",
       "      <td>0.791382</td>\n",
       "      <td>-0.153370</td>\n",
       "      <td>0.436515</td>\n",
       "      <td>112.931349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         X0        X1        X2        X3        X4        X5        X6  \\\n",
       "0 -0.644887 -0.838461 -0.541017 -0.206648  1.077663  0.596810  1.153668   \n",
       "1  0.632308  0.682364  0.326717 -0.319301 -1.271478 -0.526292 -0.213767   \n",
       "2  0.661249  0.749986  0.783604  0.330767  0.293766  0.341772 -0.284628   \n",
       "3  0.403724 -0.335054  0.579087 -0.571980 -0.751977 -0.788276  0.793930   \n",
       "4  0.485241  0.324000 -1.005675 -0.605008  0.119690  0.022500 -0.939901   \n",
       "\n",
       "         X7        X8        X9  ...       X91       X92       X93       X94  \\\n",
       "0 -0.650632  0.891848  0.951259  ... -0.447763  0.742208  1.006131  1.256626   \n",
       "1  0.472607 -0.948157 -0.460615  ...  0.927940  1.726629 -1.013680  0.658450   \n",
       "2  0.956176 -0.285018 -0.315171  ...  0.111296  0.141157 -0.860615 -1.078683   \n",
       "3 -0.309679 -0.114218 -0.232603  ... -0.324332  1.053042 -0.851262 -0.667930   \n",
       "4  1.734745  0.647245  0.830049  ...  0.258716  1.666226  1.420689  0.992014   \n",
       "\n",
       "        X95       X96       X97       X98       X99           Y  \n",
       "0  0.267859  0.428748 -0.123292  1.618648 -1.924411  -22.754639  \n",
       "1  0.591374 -1.037313  2.038828 -1.740729 -0.498542  224.417071  \n",
       "2  0.104910  1.973838 -1.676265 -0.429156  0.338231   23.856344  \n",
       "3  0.420755 -2.160269 -0.674017  1.472002  0.380672  109.627237  \n",
       "4  0.091870  2.226810  0.791382 -0.153370  0.436515  112.931349  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>...</th>\n",
       "      <th>X91</th>\n",
       "      <th>X92</th>\n",
       "      <th>X93</th>\n",
       "      <th>X94</th>\n",
       "      <th>X95</th>\n",
       "      <th>X96</th>\n",
       "      <th>X97</th>\n",
       "      <th>X98</th>\n",
       "      <th>X99</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>-0.148490</td>\n",
       "      <td>1.693809</td>\n",
       "      <td>-1.565738</td>\n",
       "      <td>1.760415</td>\n",
       "      <td>0.107343</td>\n",
       "      <td>-0.177632</td>\n",
       "      <td>-1.787913</td>\n",
       "      <td>0.382715</td>\n",
       "      <td>-1.637450</td>\n",
       "      <td>0.169869</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.353410</td>\n",
       "      <td>0.142251</td>\n",
       "      <td>1.384991</td>\n",
       "      <td>-0.870008</td>\n",
       "      <td>-0.799547</td>\n",
       "      <td>-0.731531</td>\n",
       "      <td>-0.806185</td>\n",
       "      <td>0.557439</td>\n",
       "      <td>0.196870</td>\n",
       "      <td>-234.191484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>-0.949864</td>\n",
       "      <td>-0.621252</td>\n",
       "      <td>0.505054</td>\n",
       "      <td>0.814625</td>\n",
       "      <td>-0.924541</td>\n",
       "      <td>-0.429386</td>\n",
       "      <td>-0.261202</td>\n",
       "      <td>0.046846</td>\n",
       "      <td>0.858011</td>\n",
       "      <td>0.459782</td>\n",
       "      <td>...</td>\n",
       "      <td>0.177946</td>\n",
       "      <td>-0.701649</td>\n",
       "      <td>-1.086301</td>\n",
       "      <td>1.127751</td>\n",
       "      <td>-1.279426</td>\n",
       "      <td>-0.130195</td>\n",
       "      <td>-0.185811</td>\n",
       "      <td>0.327068</td>\n",
       "      <td>1.050615</td>\n",
       "      <td>-155.852594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.219249</td>\n",
       "      <td>0.442575</td>\n",
       "      <td>0.092104</td>\n",
       "      <td>0.314288</td>\n",
       "      <td>0.437772</td>\n",
       "      <td>0.055054</td>\n",
       "      <td>-1.275508</td>\n",
       "      <td>1.305157</td>\n",
       "      <td>-0.942368</td>\n",
       "      <td>1.101025</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.432141</td>\n",
       "      <td>-0.796727</td>\n",
       "      <td>0.125273</td>\n",
       "      <td>0.424846</td>\n",
       "      <td>1.225526</td>\n",
       "      <td>0.493698</td>\n",
       "      <td>-0.500715</td>\n",
       "      <td>0.147472</td>\n",
       "      <td>-1.786110</td>\n",
       "      <td>259.366468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2.017390</td>\n",
       "      <td>0.094415</td>\n",
       "      <td>0.307489</td>\n",
       "      <td>0.587450</td>\n",
       "      <td>0.699589</td>\n",
       "      <td>-0.161504</td>\n",
       "      <td>1.883030</td>\n",
       "      <td>0.525360</td>\n",
       "      <td>0.785062</td>\n",
       "      <td>-1.835899</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.628799</td>\n",
       "      <td>-0.441302</td>\n",
       "      <td>-1.301066</td>\n",
       "      <td>-1.337402</td>\n",
       "      <td>-0.659326</td>\n",
       "      <td>0.042317</td>\n",
       "      <td>0.121978</td>\n",
       "      <td>0.331694</td>\n",
       "      <td>-1.456690</td>\n",
       "      <td>-91.824344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>-0.172222</td>\n",
       "      <td>-0.353857</td>\n",
       "      <td>-1.042769</td>\n",
       "      <td>-0.005777</td>\n",
       "      <td>1.832996</td>\n",
       "      <td>-0.341348</td>\n",
       "      <td>1.428931</td>\n",
       "      <td>-0.823251</td>\n",
       "      <td>-1.411615</td>\n",
       "      <td>0.333570</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.060633</td>\n",
       "      <td>-0.827209</td>\n",
       "      <td>-1.258697</td>\n",
       "      <td>-1.192660</td>\n",
       "      <td>-0.032599</td>\n",
       "      <td>-1.668723</td>\n",
       "      <td>0.115748</td>\n",
       "      <td>0.732320</td>\n",
       "      <td>-0.009382</td>\n",
       "      <td>-85.688192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          X0        X1        X2        X3        X4        X5        X6  \\\n",
       "95 -0.148490  1.693809 -1.565738  1.760415  0.107343 -0.177632 -1.787913   \n",
       "96 -0.949864 -0.621252  0.505054  0.814625 -0.924541 -0.429386 -0.261202   \n",
       "97  0.219249  0.442575  0.092104  0.314288  0.437772  0.055054 -1.275508   \n",
       "98  2.017390  0.094415  0.307489  0.587450  0.699589 -0.161504  1.883030   \n",
       "99 -0.172222 -0.353857 -1.042769 -0.005777  1.832996 -0.341348  1.428931   \n",
       "\n",
       "          X7        X8        X9  ...       X91       X92       X93       X94  \\\n",
       "95  0.382715 -1.637450  0.169869  ... -0.353410  0.142251  1.384991 -0.870008   \n",
       "96  0.046846  0.858011  0.459782  ...  0.177946 -0.701649 -1.086301  1.127751   \n",
       "97  1.305157 -0.942368  1.101025  ... -1.432141 -0.796727  0.125273  0.424846   \n",
       "98  0.525360  0.785062 -1.835899  ... -0.628799 -0.441302 -1.301066 -1.337402   \n",
       "99 -0.823251 -1.411615  0.333570  ... -1.060633 -0.827209 -1.258697 -1.192660   \n",
       "\n",
       "         X95       X96       X97       X98       X99           Y  \n",
       "95 -0.799547 -0.731531 -0.806185  0.557439  0.196870 -234.191484  \n",
       "96 -1.279426 -0.130195 -0.185811  0.327068  1.050615 -155.852594  \n",
       "97  1.225526  0.493698 -0.500715  0.147472 -1.786110  259.366468  \n",
       "98 -0.659326  0.042317  0.121978  0.331694 -1.456690  -91.824344  \n",
       "99 -0.032599 -1.668723  0.115748  0.732320 -0.009382  -85.688192  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(X, Y, size_, random_state_):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=size_, random_state=random_state_) \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Модели\n",
    "\n",
    "MODELS = {\n",
    "    'PLSRegression': PLSRegression(),\n",
    "    \n",
    "    'DummyRegressor': DummyRegressor(),\n",
    "    \n",
    "    'AdaBoostRegressor': AdaBoostRegressor(),\n",
    "    'BaggingRegressor': BaggingRegressor(),\n",
    "    'ExtraTreesRegressor': ExtraTreesRegressor(),\n",
    "    'GradientBoostingRegressor': GradientBoostingRegressor(),\n",
    "    'RandomForestRegressor': RandomForestRegressor(),\n",
    "    \n",
    "    #'GaussianProcessRegressor': GaussianProcessRegressor(),\n",
    "    \n",
    "    'KernelRidge': KernelRidge(),\n",
    "    \n",
    "    \n",
    "    'ARDRegression': ARDRegression(),\n",
    "    'BayesianRidge': BayesianRidge(),\n",
    "    'ElasticNet': ElasticNet(),\n",
    "    'HuberRegressor': HuberRegressor(),\n",
    "    'Lars':  Lars(),\n",
    "    'LarsCV': LarsCV(),\n",
    "    'LassoLars': LassoLars(),\n",
    "    'LinearRegression': LinearRegression(),\n",
    "    'LogisticRegression': LogisticRegression(),\n",
    "    'LogisticRegressionCV': LogisticRegressionCV(),\n",
    "    'PassiveAggressiveRegressor': PassiveAggressiveRegressor(),\n",
    "    'RANSACRegressor': RANSACRegressor(),\n",
    "    'RidgeCV': RidgeCV(),\n",
    "    'SGDRegressor': SGDRegressor()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLSRegression: 0.3371336917259041\n",
      "DummyRegressor: -7.973756620485886e+34\n",
      "AdaBoostRegressor: -0.03259866790876864\n",
      "BaggingRegressor: 0.565425114320976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Program Files\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:399: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return column_or_1d(y, warn=True)\n",
      "D:\\Program Files\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:13: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTreesRegressor: 0.530064140227033\n",
      "GradientBoostingRegressor: 0.6408236617851418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:1454: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Program Files\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:13: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor: 0.3166045195537963\n",
      "KernelRidge: 0.8013980354437449\n",
      "ARDRegression: 0.9934153586525264\n",
      "BayesianRidge: 0.7978791902355694\n",
      "ElasticNet: 0.2857702743930791\n",
      "HuberRegressor: 0.8095754192024661\n",
      "Lars: 1.0\n",
      "LarsCV: 1.0\n",
      "LassoLars: 0.9747042253430748\n",
      "LinearRegression: 0.7998265776219895\n",
      "0error: Unknown label type: 'continuous'\n",
      "0error: Unknown label type: 'continuous'\n",
      "PassiveAggressiveRegressor: 0.81167282549925\n",
      "0error: `min_samples` may not be larger than number of samples: n_samples = 70.\n",
      "RidgeCV: 0.7790048344018895\n",
      "SGDRegressor: 0.8087042104503828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Program Files\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Program Files\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Program Files\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:296: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "D:\\Program Files\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Program Files\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Program Files\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Program Files\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Program Files\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_list = []\n",
    "\n",
    "# Здесь будем хранить результаты\n",
    "TestModels = DataFrame()\n",
    "tmp = {}\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_data(X, Y, 0.30, 0)\n",
    "#for name, clf in zip(names, classifiers):\n",
    "for model_name in MODELS.keys():\n",
    "    try:\n",
    "        #ax = plt.subplot(len(datasets), len(classifiers) + 1, i)\n",
    "        model = MODELS[model_name]\n",
    "        model.fit(X_train, y_train)\n",
    "        score = model.score(X_test, y_test)\n",
    "\n",
    "        prediction = model.predict(X_test)\n",
    "\n",
    "        r2_score_ = r2_score(prediction, y_test)\n",
    "        \n",
    "        print(f\"{model_name}: {r2_score_}\")\n",
    "        if abs(r2_score_) < 2:\n",
    "            tmp['Model'] = model_name\n",
    "            tmp['R2_Y'] =  r2_score_\n",
    "            # tmp['ACCU'] =  accuracy_score(y_test, prediction)\n",
    "            TestModels = TestModels.append([tmp])\n",
    "            # try:\n",
    "            #     fpr, tpr, thresholds = roc_curve(y_test, prediction, pos_label=1)\n",
    "            #     tmp['fpr'] = fpr\n",
    "            #     tmp['tpr'] = tpr\n",
    "            #     tmp['thresholds'] = thresholds\n",
    "            # except:\n",
    "            #     print ('error roc')\n",
    "            # Записываем данные и итоговый DataFrame\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print (f\"{name}error: {e}\")\n",
    "    \n",
    "    \n",
    "TestModels.set_index('Model', inplace=True)    \n",
    "# print_list(prediction_list)\n",
    "[print(item) for item in prediction_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R2_Y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "      <td>-0.032599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElasticNet</th>\n",
       "      <td>0.285770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>0.316605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PLSRegression</th>\n",
       "      <td>0.337134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesRegressor</th>\n",
       "      <td>0.530064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingRegressor</th>\n",
       "      <td>0.565425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingRegressor</th>\n",
       "      <td>0.640824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeCV</th>\n",
       "      <td>0.779005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BayesianRidge</th>\n",
       "      <td>0.797879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.799827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KernelRidge</th>\n",
       "      <td>0.801398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGDRegressor</th>\n",
       "      <td>0.808704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HuberRegressor</th>\n",
       "      <td>0.809575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassiveAggressiveRegressor</th>\n",
       "      <td>0.811673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LassoLars</th>\n",
       "      <td>0.974704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARDRegression</th>\n",
       "      <td>0.993415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lars</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                R2_Y\n",
       "Model                               \n",
       "AdaBoostRegressor          -0.032599\n",
       "ElasticNet                  0.285770\n",
       "RandomForestRegressor       0.316605\n",
       "PLSRegression               0.337134\n",
       "ExtraTreesRegressor         0.530064\n",
       "BaggingRegressor            0.565425\n",
       "GradientBoostingRegressor   0.640824\n",
       "RidgeCV                     0.779005\n",
       "BayesianRidge               0.797879\n",
       "LinearRegression            0.799827\n",
       "KernelRidge                 0.801398\n",
       "SGDRegressor                0.808704\n",
       "HuberRegressor              0.809575\n",
       "PassiveAggressiveRegressor  0.811673\n",
       "LassoLars                   0.974704\n",
       "ARDRegression               0.993415\n",
       "Lars                        1.000000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TestModels.sort_values(by=['R2_Y']).head(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность: 1.0\n",
      "Лучшая модель: LarsCV\n"
     ]
    }
   ],
   "source": [
    "# Найти максимальное значение\n",
    "\n",
    "# ??? \n",
    "name_beast_model = ''\n",
    "for index, row in TestModels.iterrows():\n",
    "    if row['R2_Y'] == TestModels['R2_Y'].values.max():\n",
    "        name_beast_model = index\n",
    "#print ('R^2:', TestModels['R2_Y'].values.max())\n",
    "print ('Точность:', TestModels['R2_Y'].values.max())\n",
    "print ('Лучшая модель:', name_beast_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x27010f90a48>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pylab import *\n",
    "TestModels.R2_Y.plot(figsize=(10,6), kind='bar', title='R2_Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (DataFrame, Колонка для сортировки, число моделей для извлечения)\n",
    "def get_beast_model(models_df, col, reange_model=1, accuracy=None):\n",
    "    if accuracy:\n",
    "        res_list = []\n",
    "        sort_models_df = models_df.sort_values(by=[col])\n",
    "        for index, row in sort_models_df.iterrows():\n",
    "            if row[col] >= accuracy:\n",
    "                res_list.append(index)\n",
    "        return res_list\n",
    "    else:\n",
    "        temp = models_df.sort_values(by=[col])[-(reange_model):]\n",
    "        #print (temp.head(len(classifiers)))\n",
    "        result_list = []\n",
    "        for index, row in temp.iterrows():\n",
    "            result_list.append(index)\n",
    "        return result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модели точность которых выше 90.0 %\n",
      "Name model >>> LassoLars:0.9747042253430748\n",
      "Name model >>> ARDRegression:0.9934153586525264\n",
      "Name model >>> Lars:1.0\n",
      "Name model >>> LarsCV:1.0\n"
     ]
    }
   ],
   "source": [
    "accuracy = 0.90\n",
    "# Получить наименование всех моделей, точность которых выше 95%\n",
    "beast_models_name = get_beast_model(TestModels, 'R2_Y', accuracy=accuracy)\n",
    "print(f\"Модели точность которых выше {accuracy * 100} %\")\n",
    "for name_ in beast_models_name:\n",
    "    prediction = MODELS[name_].predict(X_test)\n",
    "    r2_score_ = r2_score(prediction, y_test)\n",
    "    print(f\"Name model >>> {name_}:{r2_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 лучшых моделей\n",
      "name beast model >>> PassiveAggressiveRegressor:0.81167282549925\n",
      "name beast model >>> LassoLars:0.9747042253430748\n",
      "name beast model >>> ARDRegression:0.9934153586525264\n",
      "name beast model >>> Lars:1.0\n",
      "name beast model >>> LarsCV:1.0\n"
     ]
    }
   ],
   "source": [
    "reange_model = 5\n",
    "# Получить наименование 5-ти лучших моделей\n",
    "beast_models_name = get_beast_model(TestModels, 'R2_Y', reange_model=reange_model)\n",
    "print(f\"5 лучшых моделей\")\n",
    "for name_ in beast_models_name:\n",
    "    prediction = MODELS[name_].predict(X_test)\n",
    "    r2_score_ = r2_score(prediction, y_test)\n",
    "    print(f\"name beast model >>> {name_}:{r2_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Формируем список предсказаний по каждой модели\n",
    "predict_list = []\n",
    "for model_name in beast_models_name:\n",
    "    prediction = MODELS[model_name].predict(X_test)\n",
    "    predict_list.append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность: 0.9883607497134825\n"
     ]
    }
   ],
   "source": [
    "# Методом мажоритарного голосования рассчитываем результирующее предсказание\n",
    "res_prediction = []\n",
    "# redict_list)\n",
    "for i in range(len(predict_list[0])):\n",
    "    prediction = 0\n",
    "    for j in range(len(predict_list)):\n",
    "        prediction += predict_list[j][i]\n",
    "    predict = prediction / len(predict_list)\n",
    "    res_prediction.append(predict)\n",
    "    \n",
    "res_prediction = np.array(res_prediction)\n",
    "print(f\"Точность: {r2_score(res_prediction, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
